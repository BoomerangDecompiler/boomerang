#
# This file is part of the Boomerang Decompiler.
#
# See the file "LICENSE.TERMS" for information on usage and
# redistribution of this file, and for a DISCLAIMER OF ALL
# WARRANTIES.
#

ENDIANNESS BIG;


# General Purpose registers

INTEGER %g0[32] -> 0;
INTEGER %g1[32] -> 1;
INTEGER %g2[32] -> 2;
INTEGER %g3[32] -> 3;
INTEGER %g4[32] -> 4;
INTEGER %g5[32] -> 5;
INTEGER %g6[32] -> 6;
INTEGER %g7[32] -> 7;
INTEGER %g8[32] -> 8;
INTEGER %g9[32] -> 9;
INTEGER %g10[32] -> 10;
INTEGER %g11[32] -> 11;
INTEGER %g12[32] -> 12;
INTEGER %g13[32] -> 13;
INTEGER %g14[32] -> 14;
INTEGER %g15[32] -> 15;
INTEGER %g16[32] -> 16;
INTEGER %g17[32] -> 17;
INTEGER %g18[32] -> 18;
INTEGER %g19[32] -> 19;
INTEGER %g20[32] -> 20;
INTEGER %g21[32] -> 21;
INTEGER %g22[32] -> 22;
INTEGER %g23[32] -> 23;
INTEGER %g24[32] -> 24;
INTEGER %g25[32] -> 25;
INTEGER %g26[32] -> 26;
INTEGER %g27[32] -> 27;
INTEGER %g28[32] -> 28;
INTEGER %g29[32] -> 29;
INTEGER %g30[32] -> 30;
INTEGER %g31[32] -> 31;

# FP registers
FLOAT %f0[64] -> 32;
FLOAT %f1[64] -> 33;
FLOAT %f2[64] -> 34;
FLOAT %f3[64] -> 35;
FLOAT %f4[64] -> 36;
FLOAT %f5[64] -> 37;
FLOAT %f6[64] -> 38;
FLOAT %f7[64] -> 39;
FLOAT %f8[64] -> 40;
FLOAT %f9[64] -> 41;
FLOAT %f10[64] -> 42;
FLOAT %f11[64] -> 43;
FLOAT %f12[64] -> 44;
FLOAT %f13[64] -> 45;
FLOAT %f14[64] -> 46;
FLOAT %f15[64] -> 47;
FLOAT %f16[64] -> 48;
FLOAT %f17[64] -> 49;
FLOAT %f18[64] -> 50;
FLOAT %f19[64] -> 51;
FLOAT %f20[64] -> 52;
FLOAT %f21[64] -> 53;
FLOAT %f22[64] -> 54;
FLOAT %f23[64] -> 55;
FLOAT %f24[64] -> 56;
FLOAT %f25[64] -> 57;
FLOAT %f26[64] -> 58;
FLOAT %f27[64] -> 59;
FLOAT %f28[64] -> 60;
FLOAT %f29[64] -> 61;
FLOAT %f30[64] -> 62;
FLOAT %f31[64] -> 63;

# Vector registers
INTEGER %VR0[128] -> 64;
INTEGER %VR1[128] -> 65;
INTEGER %VR2[128] -> 66;
INTEGER %VR3[128] -> 67;
INTEGER %VR4[128] -> 68;
INTEGER %VR5[128] -> 69;
INTEGER %VR6[128] -> 70;
INTEGER %VR7[128] -> 71;
INTEGER %VR8[128] -> 72;
INTEGER %VR9[128] -> 73;
INTEGER %VR10[128] -> 74;
INTEGER %VR11[128] -> 75;
INTEGER %VR12[128] -> 76;
INTEGER %VR13[128] -> 77;
INTEGER %VR14[128] -> 78;
INTEGER %VR15[128] -> 79;
INTEGER %VR16[128] -> 80;
INTEGER %VR17[128] -> 81;
INTEGER %VR18[128] -> 82;
INTEGER %VR19[128] -> 83;
INTEGER %VR20[128] -> 84;
INTEGER %VR21[128] -> 85;
INTEGER %VR22[128] -> 86;
INTEGER %VR23[128] -> 87;
INTEGER %VR24[128] -> 88;
INTEGER %VR25[128] -> 89;
INTEGER %VR26[128] -> 90;
INTEGER %VR27[128] -> 91;
INTEGER %VR28[128] -> 92;
INTEGER %VR29[128] -> 93;
INTEGER %VR30[128] -> 94;
INTEGER %VR31[128] -> 95;

INTEGER %VRSAVE[32] -> 96;
INTEGER %VSCR[32] -> 97;

# Condition Registers (contains %CR0 to %CR7)
INTEGER %CR[32] -> 99;
INTEGER %CR0[4] -> 100 SHARES %CR@[0..3];
INTEGER %CR1[4] -> 101 SHARES %CR@[4..7];
INTEGER %CR2[4] -> 102 SHARES %CR@[8..11];
INTEGER %CR3[4] -> 103 SHARES %CR@[12..15];
INTEGER %CR4[4] -> 104 SHARES %CR@[16..19];
INTEGER %CR5[4] -> 105 SHARES %CR@[20..23];
INTEGER %CR6[4] -> 106 SHARES %CR@[24..27];
INTEGER %CR7[4] -> 107 SHARES %CR@[28..31];

INTEGER %XER[32]  -> 199; # Fixed point exeption register
INTEGER %XERSO[1] -> 200 SHARES %XER@[31..31];
INTEGER %XEROV[1] -> 201 SHARES %XER@[30..30];
INTEGER %XERCA[1] -> 202 SHARES %XER@[29..29];


INTEGER %LR[32]  -> 300;     # Link Register
INTEGER %CTR[32] -> 301;     # Count Register

INTEGER %pc[32] -> -1;



SETXER(value) {
    *32* %XER := value
    *1* %XERCA := %XER@[29:29]
    *1* %XEROV := %XER@[30:30]
    *1* %XERSO := %XER@[31:31]
};

ADDFLAGSX(result, op1, op2) {
    *1*  %XERCA := ((op1@[31:31]) & (op2@[31:31])) | (~(result@[31:31]) & ((op1@[31:31]) | (op2@[31:31])))
    *1*  %XER@[29:29] := %XERCA
};

ADDFLAGSX0(result, op1, op2) {
    *1* %XERCA := ((op1@[31:31]) & (op2@[31:31])) | (~(result@[31:31]) & ((op1@[31:31]) | (op2@[31:31])))
    *1* %XER@[29:29] := %XERCA
    *1* %CR0@[0:0] := %XERSO
    *1* %CR0@[1:1] := [result = 0?1:0]
    *1* %CR0@[2:2] := [result > 0?1:0]
    *1* %CR0@[3:3] := [result < 0?1:0]
};

SUBFLAGSX(result, op1, op2) {
    *1*  %XERCA := (~(op1@[31:31]) & (op2@[31:31])) | ((result@[31:31]) & (~(op1@[31:31]) | (op2@[31:31])))
    *1*  %XER@[29:29] := %XERCA
};

SUBFLAGS0(result) {
    *1* %CR0@[0:0] := %XERSO
    *1* %CR0@[1:1] := [result = 0?1:0]
    *1* %CR0@[2:2] := [result > 0?1:0]
    *1* %CR0@[3:3] := [result < 0?1:0]
};

SUBFLAGSX0(result, op1, op2) {
    *1* %XERCA := (~(op1@[31:31]) & (op2@[31:31])) | ((result@[31:31]) & (~(op1@[31:31]) | (op2@[31:31])))
    *1* %XER@[29:29] := %XERCA
    *1* %CR0@[0:0] := %XERSO
    *1* %CR0@[1:1] := [result = 0?1:0]
    *1* %CR0@[2:2] := [result > 0?1:0]
    *1* %CR0@[3:3] := [result < 0?1:0]
};

SETFLAGS0(rd) {
    *1* %CR0@[0:0] := %XERSO            # Note: these are non IBM bit numbers; LT is most significant bit (PPC bit 0)
    *1* %CR0@[1:1] := [rd = 0?1:0]
    *1* %CR0@[2:2] := [rd > 0?1:0]
    *1* %CR0@[3:3] := [rd < 0?1:0]
};



SUBFLAGSNL(op1, op2, crfd) {
    # Set flags in Logical (unsigned) fashion
    *32* crfd = 0 => %CR0@[3:3] := op1 <u op2       *32* crfd = 0 => %CR0@[2:2] := op1 >u op2       *32* crfd = 0 => %CR0@[1:1] := op1 =  op2
    *32* crfd = 1 => %CR1@[3:3] := op1 <u op2       *32* crfd = 1 => %CR1@[2:2] := op1 >u op2       *32* crfd = 1 => %CR1@[1:1] := op1 =  op2
    *32* crfd = 2 => %CR2@[3:3] := op1 <u op2       *32* crfd = 2 => %CR2@[2:2] := op1 >u op2       *32* crfd = 2 => %CR2@[1:1] := op1 =  op2
    *32* crfd = 3 => %CR3@[3:3] := op1 <u op2       *32* crfd = 3 => %CR3@[2:2] := op1 >u op2       *32* crfd = 3 => %CR3@[1:1] := op1 =  op2
    *32* crfd = 4 => %CR4@[3:3] := op1 <u op2       *32* crfd = 4 => %CR4@[2:2] := op1 >u op2       *32* crfd = 4 => %CR4@[1:1] := op1 =  op2
    *32* crfd = 5 => %CR5@[3:3] := op1 <u op2       *32* crfd = 5 => %CR5@[2:2] := op1 >u op2       *32* crfd = 5 => %CR5@[1:1] := op1 =  op2
    *32* crfd = 6 => %CR6@[3:3] := op1 <u op2       *32* crfd = 6 => %CR6@[2:2] := op1 >u op2       *32* crfd = 6 => %CR6@[1:1] := op1 =  op2
    *32* crfd = 7 => %CR7@[3:3] := op1 <u op2       *32* crfd = 7 => %CR7@[2:2] := op1 >u op2       *32* crfd = 7 => %CR7@[1:1] := op1 =  op2
};

SUBFLAGSNS(op1, op2, crfd) {
    # Set flags in signed fashion
    *32* crfd = 0 => %CR0@[3:3] := op1 < op2        *32* crfd = 0 => %CR0@[2:2] := op1 > op2        *32* crfd = 0 => %CR0@[1:1] := op1 = op2
    *32* crfd = 1 => %CR1@[3:3] := op1 < op2        *32* crfd = 1 => %CR1@[2:2] := op1 > op2        *32* crfd = 1 => %CR1@[1:1] := op1 = op2
    *32* crfd = 2 => %CR2@[3:3] := op1 < op2        *32* crfd = 2 => %CR2@[2:2] := op1 > op2        *32* crfd = 2 => %CR2@[1:1] := op1 = op2
    *32* crfd = 3 => %CR3@[3:3] := op1 < op2        *32* crfd = 3 => %CR3@[2:2] := op1 > op2        *32* crfd = 3 => %CR3@[1:1] := op1 = op2
    *32* crfd = 4 => %CR4@[3:3] := op1 < op2        *32* crfd = 4 => %CR4@[2:2] := op1 > op2        *32* crfd = 4 => %CR4@[1:1] := op1 = op2
    *32* crfd = 5 => %CR5@[3:3] := op1 < op2        *32* crfd = 5 => %CR5@[2:2] := op1 > op2        *32* crfd = 5 => %CR5@[1:1] := op1 = op2
    *32* crfd = 6 => %CR6@[3:3] := op1 < op2        *32* crfd = 6 => %CR6@[2:2] := op1 > op2        *32* crfd = 6 => %CR6@[1:1] := op1 = op2
    *32* crfd = 7 => %CR7@[3:3] := op1 < op2        *32* crfd = 7 => %CR7@[2:2] := op1 > op2        *32* crfd = 7 => %CR7@[1:1] := op1 = op2
};

SETFFLAGSN(op1, op2, crfd) {
    # Set flags according to floating point compare
    *32* crfd = 0 => %CR0@[3:3] := op1 < op2        *32* crfd = 0 => %CR0@[2:2] := op1 > op2        *32* crfd = 0 => %CR0@[1:1] := op1 = op2
    *32* crfd = 1 => %CR1@[3:3] := op1 < op2        *32* crfd = 1 => %CR1@[2:2] := op1 > op2        *32* crfd = 1 => %CR1@[1:1] := op1 = op2
    *32* crfd = 2 => %CR2@[3:3] := op1 < op2        *32* crfd = 2 => %CR2@[2:2] := op1 > op2        *32* crfd = 2 => %CR2@[1:1] := op1 = op2
    *32* crfd = 3 => %CR3@[3:3] := op1 < op2        *32* crfd = 3 => %CR3@[2:2] := op1 > op2        *32* crfd = 3 => %CR3@[1:1] := op1 = op2
    *32* crfd = 4 => %CR4@[3:3] := op1 < op2        *32* crfd = 4 => %CR4@[2:2] := op1 > op2        *32* crfd = 4 => %CR4@[1:1] := op1 = op2
    *32* crfd = 5 => %CR5@[3:3] := op1 < op2        *32* crfd = 5 => %CR5@[2:2] := op1 > op2        *32* crfd = 5 => %CR5@[1:1] := op1 = op2
    *32* crfd = 6 => %CR6@[3:3] := op1 < op2        *32* crfd = 6 => %CR6@[2:2] := op1 > op2        *32* crfd = 6 => %CR6@[1:1] := op1 = op2
    *32* crfd = 7 => %CR7@[3:3] := op1 < op2        *32* crfd = 7 => %CR7@[2:2] := op1 > op2        *32* crfd = 7 => %CR7@[1:1] := op1 = op2
};


INSTRUCTION "MR"          (rd, rs)              { *32* rd := rs };
INSTRUCTION "LIS"         (rd, val)             { *32* rd := (val << 16) };
INSTRUCTION "LI"          (rd, val)             { *32* rd := sgnex(16, 32, val) };

# Arithmetic operations

INSTRUCTION "ADD"         (rd, ra, rb)          { *32* rd := ra + rb };
INSTRUCTION "ADDq"        (rd, ra, rb)          { *32* rd := ra + rb              SETFLAGS0(rd) };

INSTRUCTION "ADDC"        (rd, ra, rb)          { *32* rd := ra + rb              ADDFLAGSX(rd, ra, rb) };
INSTRUCTION "ADDCq"       (rd, ra, rb)          { *32* rd := ra + rb              ADDFLAGSX0(rd, ra, rb) };

INSTRUCTION "ADDE"        (rd, ra, rb)          { *32* rd := ra + rb + %XERCA };
INSTRUCTION "ADDEq"       (rd, ra, rb)          { *32* rd := ra + rb + %XERCA     SETFLAGS0(rd) };

INSTRUCTION "ADDI"        (rd, rs, simm)        { *32* rd := rs + sgnex(16, 32, simm) };
INSTRUCTION "ADDIC"       (rd, rs, simm)        { *32* rd := rs + sgnex(16, 32, simm)     ADDFLAGSX(rd, rs,  sgnex(16, 32, simm)) };   # Set carry
INSTRUCTION "ADDICq"      (rd, rs, simm)        { *32* rd := rs + sgnex(16, 32, simm)     ADDFLAGSX0(rd, rs, sgnex(16, 32, simm)) };   # Set carry and CR0
INSTRUCTION "ADDIS"       (rd, rs, simm)        { *32* rd := rs + (simm << 16) };

INSTRUCTION "ADDME"       (rd, ra)              { *32* rd := ra + %XERCA - 1 };
INSTRUCTION "ADDMEq"      (rd, ra)              { *32* rd := ra + %XERCA - 1      SETFLAGS0(rd) };

INSTRUCTION "ADDZE"       (rd, ra)              { *32* rd := ra + %XERCA };
INSTRUCTION "ADDZEq"      (rd, ra)              { *32* rd := ra + %XERCA          SETFLAGS0(rd) };

INSTRUCTION "DIVD"        (rt, ra, rb)          { *64* rt := ra / rb };
INSTRUCTION "DIVDU"       (rt, ra, rb)          { *64* rt := ra / rb };     # TODO: OV and SO are affected, too

INSTRUCTION "DIVW"        (rd, ra, rb)          { *32* rd := ra / rb };
INSTRUCTION "DIVWq"       (rd, ra, rb)          { *32* rd := ra / rb              SETFLAGS0(rd) };

INSTRUCTION "DIVWU"       (rd, ra, rb)          { *32* rd := ra / rb };
INSTRUCTION "DIVWUq"      (rd, ra, rb)          { *32* rd := ra / rb              SETFLAGS0(rd) };

INSTRUCTION "EXTSB"       (rd, ra)              { *32* rd := sgnex(8, 32, ra) };
INSTRUCTION "EXTSBq"      (rd, ra)              { *32* rd := sgnex(8, 32, ra)     SETFLAGS0(rd) };

INSTRUCTION "EXTSH"       (rd, ra)              { *32* rd := sgnex(16, 32, ra) };
INSTRUCTION "EXTSHq"      (rd, ra)              { *32* rd := sgnex(16, 32, ra)    SETFLAGS0(rd) };

INSTRUCTION "MULLI"       (rd, ra, simm)        { *32* rd := ra * sgnex(16, 32, simm) };
INSTRUCTION "MULLW"       (rd, ra, rb)          { *32* rd := ra * rb };
INSTRUCTION "MULLWq"      (rd, ra, rb)          { *32* rd := ra * rb              SETFLAGS0(rd) };

INSTRUCTION "SUBF"        (rd, ra, rb)          { *32* rd := rb - ra };
INSTRUCTION "SUBFq"       (rd, ra, rb)          { *32* rd := rb - ra              SETFLAGS0(rd) };

INSTRUCTION "SUBFE"       (rd, ra, rb)          { *32* rd := rb + %XERCA - ra };

INSTRUCTION "SUBFIC"      (rd, ra, simm)        { *32* rd := simm - ra            SUBFLAGSX(rd, simm, ra) };
INSTRUCTION "SUBFC"       (rd, ra, rb)          { *32* rd := rb - ra              SUBFLAGSX(rd, rb, ra) };

INSTRUCTION "SUBFZE"      (rt, ra)              { *32* rt := ~ra + %XERCA };
INSTRUCTION "SUBFZEq"     (rt, ra)              { *32* rt := ~ra + %XERCA         SUBFLAGS0(rt) };

INSTRUCTION "SUBFCQ"      (rd, ra, rb)          { *32* rd := rb - ra              SUBFLAGSX0(rd, rb, ra) };
INSTRUCTION "SUBFCO"      (rd, ra, rb)          { *32* rd := rb - ra              SUBFLAGSX(rd, rb, ra)  };  # Also supposed to set overflow bits
INSTRUCTION "SUBFCOQ"     (rd, ra, rb)          { *32* rd := rb - ra              SUBFLAGSX0(rd, rb, ra) }; # Also supposed to set overflow bits

INSTRUCTION "NOP"         ()                    { _ };


# Logical ops
INSTRUCTION "NEG"         (rd, ra)              { *32* rd := 0 - ra };
INSTRUCTION "NEGq"        (rd, ra)              { *32* rd := 0 - ra               SETFLAGS0(rd) };

INSTRUCTION "AND"         (rd, ra, rb)          { *32* rd := ra & rb };
INSTRUCTION "OR"          (rd, ra, rb)          { *32* rd := ra | rb };
INSTRUCTION "XOR"         (rd, ra, rb)          { *32* rd := ra ^ rb };
INSTRUCTION "ANDq"        (rd, ra, rb)          { *32* rd := ra & rb              SETFLAGS0(rd) };
INSTRUCTION "ORq"         (rd, ra, rb)          { *32* rd := ra | rb              SETFLAGS0(rd) };
INSTRUCTION "XORq"        (rd, ra, rb)          { *32* rd := ra ^ rb              SETFLAGS0(rd) };

INSTRUCTION "ANDIq"       (rd, rs, uimm)        { *32* rd := rs & uimm            SETFLAGS0(rd) };  # Only ANDIq sets flags
INSTRUCTION "ORI"         (rd, rs, uimm)        { *32* rd := rs | uimm };
INSTRUCTION "XORI"        (rd, rs, uimm)        { *32* rd := rs ^ uimm };

INSTRUCTION "ANDISq"      (rd, rs, uimm)        { *32* rd := rs & (uimm << 16)    SETFLAGS0(rd) };  # Only ANDISq sets flags
INSTRUCTION "ORIS"        (rd, rs, uimm)        { *32* rd := rs | (uimm << 16) };
INSTRUCTION "XORIS"       (rd, rs, uimm)        { *32* rd := rs ^ (uimm << 16) };

INSTRUCTION "NAND"        (rd, ra, rb)          { *32* rd := ~(ra & rb) };
INSTRUCTION "NOR"         (rd, ra, rb)          { *32* rd := ~(ra | rb) };
INSTRUCTION "EQV"         (rd, ra, rb)          { *32* rd := ~(ra ^ rb) };
INSTRUCTION "NANDq"       (rd, ra, rb)          { *32* rd := ~(ra & rb)           SETFLAGS0(rd) };
INSTRUCTION "NORq"        (rd, ra, rb)          { *32* rd := ~(ra | rb)           SETFLAGS0(rd) };
INSTRUCTION "EQVq"        (rd, ra, rb)          { *32* rd := ~(ra ^ rb)           SETFLAGS0(rd) };

# Note: no ANDI or ANDIS (ANDIq and ANDISq instead)
# Note: no XORCR/XORCRq
INSTRUCTION "ANDC"        (rd, ra, rb)          { *32* rd := ra & (~rb) };
INSTRUCTION "ORC"         (rd, ra, rb)          { *32* rd := ra | (~rb) };
INSTRUCTION "ANDCq"       (rd, ra, rb)          { *32* rd := ra & (~rb)           SETFLAGS0(rd) };
INSTRUCTION "ORCq"        (rd, ra, rb)          { *32* rd := ra | (~rb)           SETFLAGS0(rd) };


# Shifts and rotates

# Note: SRAW/SRAWI also set the carry flag (%XERCA) in some weird way
INSTRUCTION "SLW"         (Rd, Rs, op2)         { *32* Rd := Rs <<  op2 };
INSTRUCTION "SLWI"        (Rd, Rs, op2)         { *32* Rd := Rs <<  op2 };
INSTRUCTION "SRW"         (Rd, Rs, op2)         { *32* Rd := Rs >>  op2 };
INSTRUCTION "SRWI"        (Rd, Rs, op2)         { *32* Rd := Rs >>  op2 };
INSTRUCTION "SRAW"        (Rd, Rs, op2)         { *32* Rd := Rs >>A op2 };
INSTRUCTION "SRAWI"       (Rd, Rs, op2)         { *32* Rd := Rs >>A op2 };

INSTRUCTION "SLWq"        (Rd, Rs, op2)         { *32* Rd := Rs <<  op2           SETFLAGS0(Rd) };
INSTRUCTION "SRWq"        (Rd, Rs, op2)         { *32* Rd := Rs >>  op2           SETFLAGS0(Rd) };
INSTRUCTION "SRAWq"       (Rd, Rs, op2)         { *32* Rd := Rs >>A op2           SETFLAGS0(Rd) };
INSTRUCTION "SRAWIq"      (Rd, Rs, op2)         { *32* Rd := Rs >>A op2           SETFLAGS0(Rd) };

INSTRUCTION "ROTLWI"      (rd, rs, amount)      { *32* rd := rs rl amount };
INSTRUCTION "ROTLWIq"     (rd, rs, amount)      { *32* rd := rs rl amount         SETFLAGS0(rd) };
INSTRUCTION "ROTRWI"      (rd, rs, amount)      { *32* rd := rs rr amount };
INSTRUCTION "ROTRWIq"     (rd, rs, amount)      { *32* rd := rs rr amount         SETFLAGS0(rd) };


INSTRUCTION "RLWNM"       (ra, rs, rb, beg, end) {
    *32* ra := (rs rl rb) & ((1 << (32 - beg)) - (1 << (31 - end)))
};

INSTRUCTION "RLWNMq"      (ra, rs, rb, beg, end) {
    *32* ra := (rs rl rb) & ((1 << (32 - beg)) - (1 << (31 - end)))
    SETFLAGS0(ra)
};

INSTRUCTION "RLWINM"      (ra, rs, uimm, beg, end) {
    *32* ra := (rs rl uimm) & ((1 << (32 - beg)) - (1 << (31 - end)))
};

INSTRUCTION "RLWINMq"     (ra, rs, uimm, beg, end) {
    *32* ra := (rs rl uimm) & ((1 << (32 - beg)) - (1 << (31 - end)))
    SETFLAGS0(ra)
};

INSTRUCTION "RLWIMI"      (ra, rs, uimm, beg, end) {
    *32* tmp_mask := ((1 << (32 - beg)) - (1 << (31 - end)))
    *32* ra := ((rs rl uimm) & tmp_mask) | (ra & ~tmp_mask)
};

INSTRUCTION "RLWIMIq"     (ra, rs, uimm, beg, end) {
    *32* tmp_mask := ((1 << (32 - beg)) - (1 << (31 - end)))
    *32* ra := ((rs rl uimm) & tmp_mask) | (ra & ~tmp_mask)
    SETFLAGS0(ra)
};

INSTRUCTION "CLRLWI"      (rd, ra, ct) {
    *32* rd := ra@[0:(31-ct)]
};


# Memory access.
INSTRUCTION "LBZ"         (dest, src)           { *32* dest := zfill(8, 32, src)  };
INSTRUCTION "LHZ"         (dest, src)           { *32* dest := zfill(16, 32, src) };
INSTRUCTION "LWZ"         (dest, src)           { *32* dest := src };

INSTRUCTION "LBZU"        (dest, src)           { *32* dest := zfill(8, 32, src) };     # Update is hard-coded
INSTRUCTION "LHZU"        (dest, src)           { *32* dest := zfill(16, 32, src) };
INSTRUCTION "LWZU"        (dest, src)           { *32* dest := src };

INSTRUCTION "LBZX"        (rt, ra, rb)          { *32* rt := zfill(8, 32, m[ra + rb]) };
INSTRUCTION "LHZX"        (rt, ra, rb)          { *32* rt := zfill(16, 32, m[ra + rb]) };
INSTRUCTION "LWZX"        (rt, ra, rb)          { *32* rt := m[ra + rb] };

INSTRUCTION "LBZUX"       (rt, ra, rb)          { *32* rt := zfill(8,  32, m[ra + rb])     *32* ra := ra + rb };
INSTRUCTION "LHZUX"       (rt, ra, rb)          { *32* rt := zfill(16, 32, m[ra + rb])     *32* ra := ra + rb };
INSTRUCTION "LWZUX"       (rt, ra, rb)          { *32* rt := m[ra + rb]                    *32* ra := ra + rb };


INSTRUCTION "LHA"         (dest, src)           { *32* dest := sgnex(16, 32, src) };
INSTRUCTION "LHAU"        (dest, src)           { *32* dest := sgnex(16, 32, src) };        # Update is hard-coded
INSTRUCTION "LHAX"        (rt, ra, rb)          { *32* rt := m[ra + rb] };
INSTRUCTION "LHAUX"       (rt, ra, rb)          { *32* rt := m[ra + rb]                   *32* ra := ra + rb };

INSTRUCTION "LHBRX"       (rt, ra, rb)          { *16* tmp1 := m[ra + rb]                 *32* rt := tmp1@[8:15] | (tmp1@[0:7] << 8) };

INSTRUCTION "STB"         (src, dest)           { *8*  dest := truncs(32, 8, src) };
INSTRUCTION "STH"         (src, dest)           { *16* dest := truncs(32, 16, src) };
INSTRUCTION "STW"         (src, dest)           { *32* dest := src };
INSTRUCTION "STBU"        (src, dest)           { *8*  dest := truncs(32, 8, src)         *32* src := addr(dest) };
INSTRUCTION "STHU"        (src, dest)           { *16* dest := truncs(32, 16, src)        *32* src := addr(dest) };
INSTRUCTION "STWU"        (src, dest)           { *32* dest := src                        *32* src := addr(dest) };

INSTRUCTION "STBX"        (rs, ra, rb)          { *8*  m[ra + rb] := truncs(32, 8, rs) };
INSTRUCTION "STHX"        (rs, ra, rb)          { *16* m[ra + rb] := truncs(32, 16, rs) };
INSTRUCTION "STWX"        (rs, ra, rb)          { *32* m[ra + rb] := rs };
INSTRUCTION "STBUX"       (rs, ra, rb)          { *8*  m[ra + rb] := truncs(32, 8, rs)     *32* ra := ra + rb };
INSTRUCTION "STHUX"       (rs, ra, rb)          { *16* m[ra + rb] := truncs(32, 16, rs)    *32* ra := ra + rb };
INSTRUCTION "STWUX"       (rs, ra, rb)          { *32* m[ra + rb] := rs                    *32* ra := ra + rb };

INSTRUCTION "STHBRX"      (rs, ra, rb)          { *16* m[ra + rb] := (rs@[0:7] << 8)| rs@[8:15] };


# Multi word load and store (hard-coded)
INSTRUCTION "LMW"         (s, dest)     { _ };
INSTRUCTION "STMW"        (s, dest)     { _ };


# Floating point loads
INSTRUCTION "LFS"         (dest, src)           { *32* dest := fsize(32, 64, src) };
INSTRUCTION "LFSU"        (dest, src)           { *32* dest := fsize(32, 64, src) }; # Update is hard-coded
INSTRUCTION "LFD"         (dest, src)           { *64* dest := src };
INSTRUCTION "LFDU"        (dest, src)           { *64* dest := src };                # Update is hard-coded

INSTRUCTION "LFSX"        (rt, ra, rb)          { *32* rt := fsize(32, 64, m[ra + rb]) };
INSTRUCTION "LFSUX"       (rt, ra, rb)          { *32* rt := fsize(32, 64, m[ra + rb])    *32* ra := ra + rb };
INSTRUCTION "LFDX"        (rt, ra, rb)          { *64* rt := m[ra + rb] };
INSTRUCTION "LFDUX"       (rt, ra, rb)          { *64* rt := m[ra + rb]                   *32* ra := ra + rb };


# Floating point stores
INSTRUCTION "STFS"        (src, dest)           { *32* dest := fsize(64, 32, src) };
INSTRUCTION "STFSU"       (src, dest)           { *32* dest := fsize(64, 32, src) };    # Update is hard-coded
INSTRUCTION "STFD"        (src, dest)           { *64* dest := src };
INSTRUCTION "STFDU"       (src, dest)           { *64* dest := src };                   # Update is hard-coded

INSTRUCTION "STFSX"       (frs, ra, rb)         { *32* m[ra + rb] := fsize(64, 32, frs) };
INSTRUCTION "STFSUX"      (frs, ra, rb)         { *32* m[ra + rb] := fsize(64, 32, frs)   *32* ra := ra + rb };
INSTRUCTION "STFDX"       (frs, ra, rb)         { *64* m[ra + rb] := frs };
INSTRUCTION "STFDUX"      (frs, ra, rb)         { *64* m[ra + rb] := frs                  *32* ra := ra + rb };



INSTRUCTION "BALLR"       ()                    { *32* %pc := %LR };
INSTRUCTION "MFLR"        (rd)                  { *32* rd := %LR };
INSTRUCTION "MCRF"        (bf, bfa)             { *4*  bf := bfa };
INSTRUCTION "MFCR"        (rd)                  { *32* rd := (%CR0 << 28) + (%CR1 << 24)
                                             + (%CR2 << 20) + (%CR3 << 16)
                                             + (%CR4 << 12) + (%CR5 <<  8)
                                             + (%CR6 <<  4) + (%CR7) };

INSTRUCTION "MFSPR"       (rd, spr)             { *32* rd := [spr & 1 ? [spr >> 3 & 1 ? %CTR : %XER] : %LR] };
INSTRUCTION "MTLR"        (rs)                  { *32* %LR := rs };
INSTRUCTION "MTXER"       (rs)                  { SETXER(rs) };
INSTRUCTION "MTCTR"       (rs)                  { *32* %CTR := rs };

# Branches
# Semantics are hard-coded (see CapstonePPCDecoder.cpp)
INSTRUCTION "B"           (dest)                { _ };
INSTRUCTION "BA"          (dest)                { _ };
INSTRUCTION "BL"          (dest)                { _ };
INSTRUCTION "BLA"         (dest)                { _ };
INSTRUCTION "BLR"         ()                    { _ };


# Comparisons. Ignore XER[SO] for now.
INSTRUCTION "CMP"         (crfd, ra, rb)        { SUBFLAGSNS(ra, rb, crfd) };
INSTRUCTION "CMPI"        (crfd, ra, simm)      { SUBFLAGSNS(ra, sgnex(16, 32, simm), crfd) };
INSTRUCTION "CMPW"        (ra, rb)              { SUBFLAGSNS(ra, rb, 0) };
INSTRUCTION "CMPW"        (crfd, ra, rb)        { SUBFLAGSNS(ra, rb, crfd) };
INSTRUCTION "CMPWI"       (ra, simm)            { SUBFLAGSNS(ra, sgnex(16, 32, simm), 0) };
INSTRUCTION "CMPWI"       (crfd, ra, simm)      { SUBFLAGSNS(ra, sgnex(16, 32, simm), crfd) };

INSTRUCTION "CMPL"        (crfd, ra, rb)        { SUBFLAGSNL(ra, rb, crfd) };
INSTRUCTION "CMPLI"       (crfd, ra, uimm)      { SUBFLAGSNL(ra, uimm, crfd) };
INSTRUCTION "CMPLW"       (ra, rb)              { SUBFLAGSNL(ra, rb, 0) };
INSTRUCTION "CMPLW"       (crfd, ra, rb)        { SUBFLAGSNL(ra, rb, crfd) };
INSTRUCTION "CMPLWI"      (ra, uimm)            { SUBFLAGSNL(ra, uimm, 0) };
INSTRUCTION "CMPLWI"      (crfd, ra, uimm)      { SUBFLAGSNL(ra, uimm, crfd) };

INSTRUCTION "FCMPO"       (crfd, fa, fb)        { SETFFLAGSN(fa, fb,crfd) };    # Difference between O and U forms is
INSTRUCTION "FCMPU"       (crfd, fa, fb)        { SETFFLAGSN(fa, fb,crfd) };    # in exception handling


# condition register manipulation
INSTRUCTION "CRCLR"           (d)               { *1* %CR@[d:d] := 0 };
INSTRUCTION "CRSET"           (d)               { *1* %CR@[d:d] := 1 };
INSTRUCTION "CRAND"           (d, a, b)         { *1* %CR@[d:d] := %CR@[a:a] & %CR@[b:b] };
INSTRUCTION "CROR"            (d, a, b)         { *1* %CR@[d:d] := %CR@[a:a] | %CR@[b:b] };
INSTRUCTION "CRXOR"           (d, a, b)         { *1* %CR@[d:d] := %CR@[a:a] ^ %CR@[b:b] };
INSTRUCTION "CRNAND"          (d, a, b)         { *1* %CR@[d:d] := ~(%CR@[a:a] & %CR@[b:b]) };
INSTRUCTION "CRNOR"           (d, a, b)         { *1* %CR@[d:d] := ~(%CR@[a:a] | %CR@[b:b]) };
INSTRUCTION "CREQV"           (d, a, b)         { *1* %CR@[d:d] := ~(%CR@[a:a] ^ %CR@[b:b]) };
INSTRUCTION "CRANDC"          (d, a, b)         { *1* %CR@[d:d] := %CR@[a:a] & (~%CR@[b:b]) };
INSTRUCTION "CRORC"           (d, a, b)         { *1* %CR@[d:d] := %CR@[a:a] | (~%CR@[b:b]) };
# Note: no CRXORC

INSTRUCTION "MTCRF"   (mask, src) {
    *4* mask@[0:0] ~= 0 => %CR0 := src@[0:3]
    *4* mask@[1:1] ~= 0 => %CR1 := src@[4:7]
    *4* mask@[2:2] ~= 0 => %CR2 := src@[8:11]
    *4* mask@[3:3] ~= 0 => %CR3 := src@[12:15]
    *4* mask@[4:4] ~= 0 => %CR4 := src@[16:19]
    *4* mask@[5:5] ~= 0 => %CR5 := src@[20:23]
    *4* mask@[6:6] ~= 0 => %CR6 := src@[24:27]
    *4* mask@[7:7] ~= 0 => %CR7 := src@[28:31]
};

# Floating point operations
INSTRUCTION "FMR"             (fd, fb)          { *64* fd := fb };
INSTRUCTION "FMRq"            (fd, fb)          { *64* fd := fb };

INSTRUCTION "FNEG"            (fd, fb)          { *64* fd := 0.0 -f fb };
INSTRUCTION "FNEGq"           (fd, fb)          {  *64* fd := 0.0 -f fb };

INSTRUCTION "FRSP"            (fd, fb)          { *32* tmpf := fsize(64, 32, fb)        *64* fd := fsize(32, 64, tmpf) };
INSTRUCTION "FRSPq"           (fd, fb)          { *32* tmpf := fsize(64, 32, fb)        *64* fd := fsize(32, 64, tmpf) };

INSTRUCTION "FCTIW"           (fd, fb)          { *64* fd := zfill(32, 64, ftoi(64, 32, fb)) };
INSTRUCTION "FCTIWq"          (fd, fb)          { *64* fd := zfill(32, 64, ftoi(64, 32, fb)) };

# The following are supposed to round towards 0 as well
INSTRUCTION "FCTIWZ"          (fd, fb)          { *64* fd := zfill(32, 64, ftoi(64, 32, fb)) };
INSTRUCTION "FCTIWZq"         (fd, fb)          { *64* fd := zfill(32, 64, ftoi(64, 32, fb)) };

INSTRUCTION "FABS"            (fd, fs)          { *64* fd := fabs(fs) };
INSTRUCTION "FABSq"           (fd, fs)          { *64* fd := fabs(fs) }; # TODO: Update flags
INSTRUCTION "FNABS"           (fd, fs)          { *64* fd := 0.0 -f fabs(fs) };
INSTRUCTION "FNABSq"          (fd, fs)          { *64* fd := 0.0 -f fabs(fs) }; # TODO: Update flags

INSTRUCTION "FADD"            (fd, fa, fb)      {  *64* fd := fa +f fb };
INSTRUCTION "FADDq"           (fd, fa, fb)      { *64* fd := fa +f fb };        # Note: floating point flags not implemented yet
INSTRUCTION "FADDS"           (fd, fa, fb)      { *64* fd := fa +f fb };        # Note: may only operate on 32 bits of precision
INSTRUCTION "FADDSq"          (fd, fa, fb)      { *64* fd := fa +f fb };

INSTRUCTION "FSUB"            (fd, fa, fb)      { *64* fd := fa -f fb };
INSTRUCTION "FSUBq"           (fd, fa, fb)      { *64* fd := fa -f fb };
INSTRUCTION "FSUBS"           (fd, fa, fb)      { *64* fd := fa -f fb };        # Note as above
INSTRUCTION "FSUBSq"          (fd, fa, fb)      { *64* fd := fa -f fb };

INSTRUCTION "FMUL"            (fd, fa, fb)      { *64* fd := fa *f fb };
INSTRUCTION "FMULq"           (fd, fa, fb)      { *64* fd := fa *f fb };
INSTRUCTION "FMULS"           (fd, fa, fb)      { *64* fd := fa *f fb };
INSTRUCTION "FMULSq"          (fd, fa, fb)      { *64* fd := fa *f fb };

INSTRUCTION "FDIV"            (fd, fa, fb)      { *64* fd := fa /f fb };
INSTRUCTION "FDIVq"           (fd, fa, fb)      { *64* fd := fa /f fb };
INSTRUCTION "FDIVS"           (fd, fa, fb)      { *64* fd := fa /f fb };        # Note: only operates on 64/32 bits of precision
INSTRUCTION "FDIVSq"          (fd, fa, fb)      { *64* fd := fa /f fb };        # Yet result is in 64-bit format

INSTRUCTION "FMADD"           (ft, fa, fc, fb)  { *64* ft := (fa *f fc) +f fb };
INSTRUCTION "FMADDq"          (ft, fa, fc, fb)  { *64* ft := (fa *f fc) +f fb }; # TODO: Update flags
INSTRUCTION "FMADDS"          (ft, fa, fc, fb)  { *64* ft := (fa *f fc) +f fb };
INSTRUCTION "FMADDSq"         (ft, fa, fc, fb)  { *64* ft := (fa *f fc) +f fb }; # TODO: Update flags

INSTRUCTION "FMSUB"           (ft, fa, fc, fb)  { *64* ft := (fa *f fc) -f fb };
INSTRUCTION "FMSUBq"          (ft, fa, fc, fb)  { *64* ft := (fa *f fc) -f fb }; # TODO: Update flags
INSTRUCTION "FMSUBS"          (ft, fa, fc, fb)  { *64* ft := (fa *f fc) -f fb };
INSTRUCTION "FMSUBSq"         (ft, fa, fc, fb)  { *64* ft := (fa *f fc) -f fb }; # TODO: Update flags

INSTRUCTION "FNMADD"          (ft, fa, fc, fb)  { *64* ft := 0.0 -f ((fa *f fc) +f fb) };
INSTRUCTION "FNMADDq"         (ft, fa, fc, fb)  { *64* ft := 0.0 -f ((fa *f fc) +f fb) };
INSTRUCTION "FNMADDS"         (ft, fa, fc, fb)  { *64* ft := 0.0 -f ((fa *f fc) +f fb) };
INSTRUCTION "FNMADDSq"        (ft, fa, fc, fb)  { *64* ft := 0.0 -f ((fa *f fc) +f fb) };

INSTRUCTION "FNMSUB"          (ft, fa, fc, fb)  { *64* ft := 0.0 -f ((fa *f fc) -f fb) };
INSTRUCTION "FNMSUBq"         (ft, fa, fc, fb)  { *64* ft := 0.0 -f ((fa *f fc) -f fb) };
INSTRUCTION "FNMSUBS"         (ft, fa, fc, fb)  { *64* ft := 0.0 -f ((fa *f fc) -f fb) };
INSTRUCTION "FNMSUBSq"        (ft, fa, fc, fb)  { *64* ft := 0.0 -f ((fa *f fc) -f fb) };

INSTRUCTION "FRES"            (fd, fb)          { *32* fd := 1 /f fb };
INSTRUCTION "FRESq"           (fd, fb)          { *32* fd := 1 /f fb }; # TODO Update flags

INSTRUCTION "FSQRT"           (fd, fb)          { *64* fd := sqrt(fb) };
INSTRUCTION "FSQRTq"          (fd, fb)          { *64* fd := sqrt(fb) };
INSTRUCTION "FSQRTS"          (fd, fb)          { *64* fd := sqrt(fb) };
INSTRUCTION "FSQRTSq"         (fd, fb)          { *64* fd := sqrt(fb) };


# conditional branch
# MVE: Not sure if I have the bit numbers round the right way (is LT 3 or 0?)
#
#CONDBR :=     { "%CR0@[3:3]",   "~%CR0@[2:2]",  "%CR0@[1:1]",   "~%CR0@[3:3]",
#                "%CR0@[2:2]",   "~%CR0@[3:3]",  "~%CR0@[1:1]",  "~%CR0@[2:2]",
#                "%CR0@[0:0]",   "~%CR0@[0:0]",  "%CR0@[0:0]",   "~%CR0@[0:0]"} };
#
# Note: The semantics for the instructions below are still hard-coded so they are not defined explicitly.

# BRCONDS[IDX]    BIcr, reloc     *32* %pc := [(CONDBR[IDX] = 1) ? %pc+reloc : %pc] };
INSTRUCTION "blt"     ()               { _ };
INSTRUCTION "blt"     (dest)           { _ };
INSTRUCTION "blt"     (cr, dest)       { _ };
INSTRUCTION "ble"     ()               { _ };
INSTRUCTION "ble"     (dest)           { _ };
INSTRUCTION "ble"     (cr, dest)       { _ };
INSTRUCTION "beq"     ()               { _ };
INSTRUCTION "beq"     (dest)           { _ };
INSTRUCTION "beq"     (cr, dest)       { _ };
INSTRUCTION "bge"     ()               { _ };
INSTRUCTION "bge"     (dest)           { _ };
INSTRUCTION "bge"     (cr, dest)       { _ };
INSTRUCTION "bgt"     ()               { _ };
INSTRUCTION "bgt"     (dest)           { _ };
INSTRUCTION "bgt"     (cr, dest)       { _ };
INSTRUCTION "bnl"     ()               { _ };
INSTRUCTION "bnl"     (dest)           { _ };
INSTRUCTION "bnl"     (cr, dest)       { _ };
INSTRUCTION "bne"     ()               { _ };
INSTRUCTION "bne"     (dest)           { _ };
INSTRUCTION "bne"     (cr, dest)       { _ };
INSTRUCTION "bng"     ()               { _ };
INSTRUCTION "bng"     (dest)           { _ };
INSTRUCTION "bng"     (cr, dest)       { _ };


# BRCONDSCTR[IDX] BIcr            *32* %pc := [(CONDBR[IDX] = 1) ? %CTR : %pc] };
INSTRUCTION "bltctr"  (BIcr)           { _ };
INSTRUCTION "blectr"  (BIcr)           { _ };
INSTRUCTION "beqctr"  (BIcr)           { _ };
INSTRUCTION "bgectr"  (BIcr)           { _ };
INSTRUCTION "bgtctr"  (BIcr)           { _ };
INSTRUCTION "bnlctr"  (BIcr)           { _ };
INSTRUCTION "bnectr"  (BIcr)           { _ };
INSTRUCTION "bngctr"  (BIcr)           { _ };

# BRCONDSLR[IDX]  BIcr            *32* %pc := [(CONDBR[IDX] = 1) ? %LR : %pc] };
INSTRUCTION "bltlr"  (BIcr)            { _ };
INSTRUCTION "blelr"  (BIcr)            { _ };
INSTRUCTION "beqlr"  (BIcr)            { _ };
INSTRUCTION "bgelr"  (BIcr)            { _ };
INSTRUCTION "bgtlr"  (BIcr)            { _ };
INSTRUCTION "bnllr"  (BIcr)            { _ };
INSTRUCTION "bnelr"  (BIcr)            { _ };
INSTRUCTION "bnglr"  (BIcr)            { _ };

# Decrement CTR, branch conditionally
INSTRUCTION "BDNZ"    (dest)           { _ }; # %pc update is hard-coded
INSTRUCTION "BDNZL"   (dest)           { *j32* %LR := dest };      # %pc update is hard-coded

INSTRUCTION "BCTR"    ()               { _ }; # hard-coded
INSTRUCTION "BCTRL"   ()               { _ }; # hard-coded

# Trap instructions
INSTRUCTION "TDI"     (cc, ra, simm)   { _ };
INSTRUCTION "TDGTI"   (ra, simm)       { _ };
INSTRUCTION "TDLTI"   (ra, simm)       { _ };
INSTRUCTION "TDLGTI"  (ra, simm)       { _ };
INSTRUCTION "TDLLTI"  (ra, simm)       { _ };
INSTRUCTION "TDNEI"   (ra, simm)       { _ };
INSTRUCTION "TDEQI"   (ra, simm)       { _ };
INSTRUCTION "TDUI"    (ra, simm)       { _ };

INSTRUCTION "TWI"     (cc, ra, simm) { _ };
INSTRUCTION "TWGTI"   (ra, simm)     { _ };
INSTRUCTION "TWLTI"   (ra, simm)     { _ };
INSTRUCTION "TWNEI"   (ra, simm)     { _ };
INSTRUCTION "TWLGTI"  (ra, simm)     { _ };
INSTRUCTION "TWLLTI"  (ra, simm)     { _ };
INSTRUCTION "TWEQI"   (ra, simm)     { _ };
INSTRUCTION "TWUI"    (ra, simm)     { _ };

# Vector instructions
INSTRUCTION "VADDCUW" (vd, va, vb) {
    *64* tmp1 := zfill(32, 64, va@[0:31])   + zfill(32, 64, vb@[0:31])
    *64* tmp2 := zfill(32, 64, va@[32:63])  + zfill(32, 64, vb@[32:63])
    *64* tmp3 := zfill(32, 64, va@[64:95])  + zfill(32, 64, vb@[64:95])
    *64* tmp4 := zfill(32, 64, va@[96:127]) + zfill(32, 64, vb@[96:127])
    *32* vd@[0:31]   := zfill(1, 32, tmp1@[32:32])
    *32* vd@[32:63]  := zfill(1, 32, tmp2@[32:32])
    *32* vd@[64:95]  := zfill(1, 32, tmp3@[32:32])
    *32* vd@[96:127] := zfill(1, 32, tmp4@[32:32])
};

INSTRUCTION "VADDFP" (vd, va, vb) {
    *32* vd@[0:31]   := va@[0:31]   +f vb@[0:31]
    *32* vd@[32:63]  := va@[32:63]  +f vb@[32:63]
    *32* vd@[64:95]  := va@[64:95]  +f vb@[64:95]
    *32* vd@[96:127] := va@[96:127] +f vb@[96:127]
};


INSTRUCTION "VADDUBM" (vd, va, vb) {
    *8* vd@[0:7]     := (va@[0:7]     + vb@[0:7])     & 0xFF
    *8* vd@[8:15]    := (va@[8:15]    + vb@[8:15])    & 0xFF
    *8* vd@[16:23]   := (va@[16:23]   + vb@[16:23])   & 0xFF
    *8* vd@[24:31]   := (va@[24:31]   + vb@[24:31])   & 0xFF
    *8* vd@[32:39]   := (va@[32:39]   + vb@[32:39])   & 0xFF
    *8* vd@[40:47]   := (va@[40:47]   + vb@[40:47])   & 0xFF
    *8* vd@[48:55]   := (va@[48:55]   + vb@[48:55])   & 0xFF
    *8* vd@[56:63]   := (va@[56:63]   + vb@[56:63])   & 0xFF
    *8* vd@[64:71]   := (va@[64:71]   + vb@[64:71])   & 0xFF
    *8* vd@[72:79]   := (va@[72:79]   + vb@[72:79])   & 0xFF
    *8* vd@[80:87]   := (va@[80:87]   + vb@[80:87])   & 0xFF
    *8* vd@[88:95]   := (va@[88:95]   + vb@[88:95])   & 0xFF
    *8* vd@[96:103]  := (va@[96:103]  + vb@[96:103])  & 0xFF
    *8* vd@[104:111] := (va@[104:111] + vb@[104:111]) & 0xFF
    *8* vd@[112:119] := (va@[112:119] + vb@[112:119]) & 0xFF
    *8* vd@[120:127] := (va@[120:127] + vb@[120:127]) & 0xFF
};

INSTRUCTION "VADDUHM" (vd, va, vb) {
    *16* vd@[0:15]    := (va@[0:15]    + vb@[0:15])    & 0xFFFF
    *16* vd@[15:31]   := (va@[15:31]   + vb@[15:31])   & 0xFFFF
    *16* vd@[32:47]   := (va@[32:47]   + vb@[32:47])   & 0xFFFF
    *16* vd@[48:63]   := (va@[48:63]   + vb@[48:63])   & 0xFFFF
    *16* vd@[64:79]   := (va@[64:79]   + vb@[64:79])   & 0xFFFF
    *16* vd@[80:95]   := (va@[80:95]   + vb@[80:95])   & 0xFFFF
    *16* vd@[96:111]  := (va@[96:111]  + vb@[96:111])  & 0xFFFF
    *16* vd@[112:127] := (va@[112:127] + vb@[112:127]) & 0xFFFF
};

INSTRUCTION "VADDUWM" (vd, va, vb) {
    *32* vd@[0:31]    := (va@[0:31]    + vb@[0:31])    & 0xFFFFFFFF
    *32* vd@[32:63]   := (va@[32:63]   + vb@[32:63])   & 0xFFFFFFFF
    *32* vd@[64:95]   := (va@[64:95]   + vb@[64:95])   & 0xFFFFFFFF
    *32* vd@[96:127]  := (va@[96:127]  + vb@[96:127])  & 0xFFFFFFFF
};

INSTRUCTION "VAND" (vd, va, vb) {
    *128* vd := va & vb
};

INSTRUCTION "VANDC" (vd, va, vb) {
    *128* vd := va & ~vb
};

INSTRUCTION "VSR" (vd, va, vb) {
    *128* vd := va >> vb@[125:127]
};

INSTRUCTION "VUPKLSH" (vd, vb) {
    *32* vd@[0:31]   := sgnex(16, 32, vb@[0:15])
    *32* vd@[32:63]  := sgnex(16, 32, vb@[16:31])
    *32* vd@[64:95]  := sgnex(16, 32, vb@[32:47])
    *32* vd@[96:127] := sgnex(16, 32, vb@[48:63])
};

INSTRUCTION "VXOR" (vd, va, vb) {
    *128* vd := va ^ vb
};

# Misc other instructions
INSTRUCTION "ATTN" () { _ };
